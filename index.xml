<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Stan Pepels on Stan Pepels</title>
    <link>https://stanpepels.github.io/</link>
    <description>Recent content in Stan Pepels on Stan Pepels</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Your Name</copyright>
    <lastBuildDate>Wed, 20 Apr 2016 00:00:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Custom physics</title>
      <link>https://stanpepels.github.io/project/custom-physics/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://stanpepels.github.io/project/custom-physics/</guid>
      <description>&lt;p&gt;&lt;strong&gt;2D Physics engine:&lt;/strong&gt; The 2D physics engine uses impulse based collision resolution to resolve things like linear velocity, angular velocity and friction. In order to do collision I could&amp;rsquo;ve used the seperating axis theorem but instead decided to go for GJK to challange myself (SAT would&amp;rsquo;ve been faster and more performant however).
For a broadphase collision detection I went for a simple quadtree due to project time constraints. The supported colliders are sphere, box and convex hull.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tooling:&lt;/strong&gt; The physics engine came with a couple of custom inspectors that could be used to debug the engine and modify physics objects. Besides these tools I also build a level editor for the game that would use this physics engine.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>dear father</title>
      <link>https://stanpepels.github.io/project/dear-father/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://stanpepels.github.io/project/dear-father/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Dialogue tree tool:&lt;/strong&gt; Most of my work during this short project went towards creating a tool for the designers to implement their dialogues. The decision to make a tool
in such a short-term project came from the fact that this entire game is based on dialogues. The dialogue tree itself is an extension of unreal behavior trees.
We made a couple of custom nodes.
&lt;ul&gt;
&lt;li&gt;The first node was a &lt;strong&gt;decorator&lt;/strong&gt;. This decorator holds a question to be displayed and some possible answers. Each answer can be assigned points or an animation.&lt;/li&gt;
&lt;li&gt;The second custom node was an &lt;strong&gt;action&lt;/strong&gt; namely the wait for answer node. As the name suggests this would pause the tree and wait for the user to select an answer. &lt;/li&gt;
&lt;li&gt;The final node is another &lt;strong&gt;action&lt;/strong&gt;. This final node would stop the conversation.&lt;/li&gt;
&lt;/ul&gt;
When constructing a dialogue tree the designer would use a selector node(provided by unreal) and place the dialogue decorator on it. The next step for the designer
would be to fill in the decorator fields. After the decoration was set the designers would create the wait for answer action and create more selector nodes
(1 node for each answer). In the decorator the answers are numbered from 0 to N. In the tree the next nodes would be read from left to right thus answer 0 would move to the
leftmost node. This process would then be repeated to build the entire dialogue.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>orbis</title>
      <link>https://stanpepels.github.io/project/orbis/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://stanpepels.github.io/project/orbis/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Controller:&lt;/strong&gt; The main responsibility of the controller that I had was the input. The main issue that we faced with the input was that we needed to capture the separate input from multiple mice.
This was achieved with help from a third party library. Besides doing the input I also had a hand in building the actual controller.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gameplay:&lt;/strong&gt; Regarding gameplay I did the &amp;lsquo;bumping behavior&amp;rsquo; and the audio implementation. The bumping was only in applied if your velocity would align with the collision normal. Then by projecting the velocity onto the collision normal
I would determine the total amount of force used to bump the other player away. The player would also be immune to bumping until it has touched down on the platform. This was done to prevent spawn camping.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>clouded</title>
      <link>https://stanpepels.github.io/project/clouded/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://stanpepels.github.io/project/clouded/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Cloud behaviour:&lt;/strong&gt; The movement of the cloud particles was achieved using a vector field. This field is then manipulated by holding a button on the Vive controller and dragging it around the air.
In order to smooth out the movement, a simple box blur is applied to the vector field.&lt;/p&gt;

&lt;p&gt;The creation of rain and thunderstorm clouds was done by using simple spatial partitioning. The cloud layer would be divided into a grid and all small cloud particles would be inserted in this grid. Then depending on
the density of a grid cell, the algorithm would start checking its neighbors. If the neighbors also exceeded the density threshold they would be added to a list and the same would be done for the newfound cells (much like a flood fill algorithm).
In the end, the bounding box of all neighboring cells would calculated, and if big enough all particles would be removed and a rain cloud would be created. Depending on the number of particles removed the rain would be more severe or last longer.
For dry areas, the same algorithm could be used but except for checking if a cell exceeds a value, I would check if the density was below a specified value.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Controller input / UI:&lt;/strong&gt; For controller input there are only 2 buttons used. The trigger on the back of the controller is used to manipulate the cloud movement. The circular touchpad
is used to navigate the menus. The reason for using the touchpad for menus is that it comes close to using a mouse. When you put your thumb on the touchpad a small sphere is displayed on the menu.
This sphere indicated your thumb position on the touchpad. By then moving your thumb over the touchpad the sphere would move across the menu and you can select something by clicking the touchpad. This gave
some intuitive controls to menus that did not require any pointing of lasers at a plane.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>project sulphur</title>
      <link>https://stanpepels.github.io/project/project-sulphur/</link>
      <pubDate>Mon, 20 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://stanpepels.github.io/project/project-sulphur/</guid>
      <description>&lt;p&gt;Project sulphur can be subdivided into 3 catagories: engine, builder and editor. &lt;br&gt;
&lt;ul&gt;
    &lt;li&gt;&lt;strong&gt;The engine:&lt;/strong&gt; is the library with all the functionality required to run the game such as rendering, physics, networking etc&amp;hellip; This is completely written in C++.
    &lt;li&gt;&lt;strong&gt;The builder:&lt;/strong&gt; is a standalone command line tool that is used to package raw assets into game-ready formats used by the engine. Like the engine, this is written in C++.
    &lt;li&gt;&lt;strong&gt;The editor:&lt;/strong&gt; is the environment where the features of the engine are exposed in a user-friendly interface. This is where you can create your game projects, levels etc&amp;hellip; The editor is mainly written in C#/xaml but uses some DLLs written in C++.
&lt;/ul&gt;&lt;/p&gt;

&lt;div style=&#34;position: relative;&#34;&gt;
    
    &lt;strong&gt;Engine work:&lt;/strong&gt; My main work on the engine is on the interfaces that allow the engine to communicate with the engine. The engine is connected to the editor via the network.
This means that the engine you see in the editor is its own separate process. Another benefit of this connection is that we could, in theory, launch a second or even a third engine in editor mode and have all engines connect to a single editor instance.
These other versions could run on other machines such as a PS4 devkit. This, in turn, would then allow for simultaneous testing and developing for multiple platforms without having to switch around platforms or create a build before testing.
    
&lt;/div&gt;

&lt;p&gt;&lt;div style=&#34;float: right; position: relative; width: 50%;&#34;&gt;
    &lt;div&gt;
        &lt;img src=&#34;https://stanpepels.github.io/gifs/sulphur-builder.gif&#34; style=&#34;display: block;
  width: 100%;
             
             margin: 5% 0% 0% 0%;&#34;/&gt;
                                      
    &lt;/div&gt;
    
    &lt;div style=&#34;text-align: center; font-size: 70%; margin-bottom: 0%;&#34;&gt;Converting multiple assets types using the sulphur builder.&lt;/div&gt;
    
&lt;/div&gt;
&lt;div style=&#34;position: relative;&#34;&gt;
    
    &lt;strong&gt;Builder work:&lt;/strong&gt; With the builder I mainly worked on the command line interfaces. These interfaces allow other programmers to easily add commands with flags and arguments to the builder. I was also responsible for doing the shader pipeline.
The shader pipeline takes in a shader written in hlsl with some custom definitions. This single file is then converted into a shader package that can be loaded by the engine and used to render with Directx12, Vulkan, and GNM(PS4).
    
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;&lt;div style=&#34;float: left; position: relative; width: 50%;&#34;&gt;
    &lt;div&gt;
        &lt;img src=&#34;https://stanpepels.github.io/gifs/sulphur-editor.gif&#34; style=&#34;display: block;
  width: 100%;
             
             margin: 3% 0% 0% -3%;&#34;/&gt;
                                      
    &lt;/div&gt;
    
    &lt;div style=&#34;text-align: center; font-size: 70%; margin-bottom: 0%;&#34;&gt;Assets can also be imported in the editor and instantiated in the world.&lt;/div&gt;
    
&lt;/div&gt;
&lt;div style=&#34;position: relative;&#34;&gt;
    
    &lt;p&gt;&lt;strong&gt;Editor work:&lt;/strong&gt; Most of my contribution in this project was with the editor. I wrote the interface and utility classes that allow the editor to receive, process and send messages to connected engines.
I also wrote an interface that allows controls and systems to be developed completely separate whilst still being able to act upon actions or event that happen in different systems. Besides this, I was responsible for creating the world-view, asset browser, logger, and menu bar.
The editor also has a project pipeline allowing you to set up multiple game projects. Each project can be shared with other people since all paths are relative.&lt;/p&gt;

&lt;p&gt;Under the hood, the editor uses a DLL version of the sulphur builder. I worked on exposing the sulphur builder(written in C++) functionality to C# so it can be used by the editor.&lt;/p&gt;

    
&lt;/div&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AGR</title>
      <link>https://stanpepels.github.io/project/agr/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://stanpepels.github.io/project/agr/</guid>
      <description>&lt;p&gt;&lt;div style=&#34;float: right; position: relative; width: 40%;&#34;&gt;
    &lt;div&gt;
        &lt;img src=&#34;https://stanpepels.github.io/img/AGR/Maya%20engine%20attributes.png&#34; style=&#34;display: block;
  width: 100%;
             
             margin: 2% 0% 0% 0%;&#34;/&gt;
                                      
    &lt;/div&gt;
    
    &lt;div style=&#34;text-align: center; font-size: 70%; margin-bottom: 0%;&#34;&gt;Custom attributes added to a Maya root object&lt;/div&gt;
    
&lt;/div&gt;
&lt;strong&gt;Maya C++ plugin&lt;/strong&gt; My main work on this project was done on the Maya plugin. When this plugin is installed together with the Houdini tools our artists provided it would extend Maya by giving objects extra attributes.
These attributes are engine features such as collision shapes/dimensions, setting collision layers, setting the object types etc. Besides this, it came with an exporter. This would use the Houdini tools to generate the collision mesh and
visual mesh of the track. This would also generate all the waypoints used by the lap system in the engine. In order to allow for jumps, a designer could create multiple &amp;lsquo;tracks&amp;rsquo; in the same level and link them up using the Maya node editor.&lt;/p&gt;

&lt;p&gt;The export has 2 settings, Debug and Release. Debug would use the collision mesh as its visual mesh thus reducing the export time by a lot.
In order to speed up export, even more, the export was multithreaded since the number of vertices put out by Houdini could be a lot depending on the Houdini tool settings the designer used
(before multithreading a release export could take up to 2.5 min with 3.3 million vertices. After the multithreading the same export took 41 seconds).
The outputted file is a binary file that could be fed directly to the engine.
&lt;div style=&#34;float: right; position: relative; width: 100%;&#34;&gt;
    &lt;div&gt;
        &lt;img src=&#34;https://stanpepels.github.io/img/AGR/May-nodes.png&#34; style=&#34;display: block;
  width: 100%;
             
             margin: 0% 0% 0% 0%;&#34;/&gt;
                                      
    &lt;/div&gt;
    
    &lt;div style=&#34;text-align: center; font-size: 70%; margin-bottom: 3%;&#34;&gt;Multiple track parts could be linked up to create one coherent track. This allowed for jumps and splits. The voodoo track nodes were created by the plugin and would take a Houdini tool object as input.&lt;/div&gt;
    
&lt;/div&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Input:&lt;/strong&gt; For the input I wrote an interface that works cross-platform for both PC and PS4 although the game could only be played using a controller. On windows, I used Xinput for handling controller support. The mouse and keyboard were used to tweak the game with ImGui
The interfaced followed the listener pattern. That is to say in order to receive input an object had to be registered with a single input processing system.&lt;/p&gt;

&lt;p&gt;&lt;div style=&#34;float: right; position: relative; width: 40%;&#34;&gt;
    &lt;div&gt;
        &lt;img src=&#34;https://stanpepels.github.io/gifs/physXdebugger.gif&#34; style=&#34;display: block;
  width: 100%;
             
             margin: 0% 0% 0% 0%;&#34;/&gt;
                                      
    &lt;/div&gt;
    
    &lt;div style=&#34;text-align: center; font-size: 70%; margin-bottom: 0%;&#34;&gt;The PhysX debugger could be used to debug the physics scene.&lt;/div&gt;
    
&lt;/div&gt;
&lt;strong&gt;PhysX:&lt;/strong&gt; Our PhysX implementation exposed most of the PhysX functionalities. Such as collision filtering and ray casts. It would also send out callback in a unity style interface but then written in C++. All most common collision shapes where supported
i.e. Capsule, Sphere, Box, Mesh, Convex hull and height maps. In debug mode, the PhysX visual debugger could be attached to view and debug the physics scene.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gameplay Features:&lt;/strong&gt; With regards to gameplay I was responsible for one of the early iterations of the vehicle behavior. Besides that, I also worked on the lap system that was built in the engine and on the different object types that are available in the engine.
We did not use an entity component system like unity because of time constraints and the specific target game of the engine could do without.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AbDuckTed</title>
      <link>https://stanpepels.github.io/project/abduckted/</link>
      <pubDate>Mon, 20 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://stanpepels.github.io/project/abduckted/</guid>
      <description>&lt;p&gt;&lt;strong&gt;UI:&lt;/strong&gt; With the UI I was responsible for implementing the score counter, the item bar, and the win / lose screens. I also did the drag and drop behavior for the towers. The placing was done by doing a simple ray from the mouse
into the scene and check against the grid.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>NIMBY</title>
      <link>https://stanpepels.github.io/project/nimby/</link>
      <pubDate>Mon, 20 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://stanpepels.github.io/project/nimby/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Leaf Spawning:&lt;/strong&gt; For the leaf spawning I made a script that would spawn leaves at a random position in a circle. The script allowed the designers to tweak the spawn rate of the leaves. Besides the spawn rate, it was
also possible to restrict the spawning to a quarter circle, a half circle, and a three-quarter circle. It was also possible to specify a minimum radius thus spawning leaves in adult shape. Each level also had a spawner manager.
This object would control all spawners to make sure that the maximum amount of spawned leaves on the entire field would not exceed a certain threshold.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Leaf behavior/leaf blower:&lt;/strong&gt; The leaf behavior was done by applying a velocity based on the angle between the player forward vector and the vector from the leaf to the player. Also the closer the player
to the leaf the higher the magnitude of the force. A random rotation was also applied to the leaf to make a bit more visually appealing.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Choosing a framework for tool development</title>
      <link>https://stanpepels.github.io/post/tools-framework/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>https://stanpepels.github.io/post/tools-framework/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;One of the first decisions to make when thinking about building a toolset is what framework you are going to use. Since there are quite a few options out there it can be a pretty hard decision as to what framework you’d want to go for. Every framework comes with its pros and cons. When I was deciding which framework to use I selected the following candidates:
&lt;ol&gt;
&lt;li&gt;&lt;b&gt;ATF:&lt;/b&gt; On paper, this framework looks perfect for our needs. It’s build upon WinForms C# and is built specifically for developing game development tools. Besides this, it’s documentation seems to very extensive.&lt;/li&gt;&lt;/p&gt;

&lt;p&gt;&lt;li&gt;&lt;b&gt;QT:&lt;/b&gt; QT is a C   library for creating UI applications. A lot of good apps have been created using QT which proves it capabilities. Another big plus is of course that it’s written in C  , a language I’m familiar with and gives a lot of low level control and speed.&lt;/li&gt;&lt;/p&gt;

&lt;p&gt;&lt;li&gt;&lt;b&gt;WPF:&lt;/b&gt; WPF (Windows Presentation Foundation) is the successor of WinForms and, like WinForms, it’s build upon the .NET framework and written in C#. It also uses xaml as a mark-up language and was built to have better performance than WinForms.&lt;/li&gt;
&lt;/ol&gt;
My goal was to get an external renderer working in all frameworks and see which one was the easiest to implement.&lt;/p&gt;

&lt;h2 id=&#34;atf&#34;&gt;ATF&lt;/h2&gt;

&lt;p&gt;One thing I soon discovered when working with ATF is that it’s no longer as well maintained as it used to be. In the first place, it’s no longer being developed by Sony WWS. Secondly, the open forums are deserted with the most recent post originating from 2015. This wouldn’t be a problem if the framework itself wasn’t hard to learn. But as it turns out, it has a very steep learning curve. These things combined made it hard to get anything working properly. And besides this, there are a few other quirks that make this framework worse than when I initially heard about it. Here are a few of the other things that hindered my development:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;    It’s based on WinForms, but how the use WinForms is unclear.&lt;/li&gt;
&lt;li&gt;    It has a lot of third party dependencies (13 in total if you choose to use all available modules).&lt;/li&gt;
&lt;li&gt;    The samples are unclear as to what they do and how systems talk to each other.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;i&gt;Summary:&lt;/i&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;th&gt;Pros&lt;/th&gt;
&lt;th&gt;Cons&lt;/th&gt;
&lt;/tr&gt;&lt;/p&gt;

&lt;p&gt;&lt;tr&gt;
&lt;td&gt;Mature codebase&lt;/td&gt;
&lt;td&gt;It has a very steep learning curve&lt;/td&gt;
&lt;/tr&gt;&lt;/p&gt;

&lt;p&gt;&lt;tr&gt;
&lt;td&gt;It’s very flexible (MEF based)&lt;/td&gt;
&lt;td&gt;It’s no longer under active development&lt;/td&gt;
&lt;/tr&gt;&lt;/p&gt;

&lt;p&gt;&lt;tr&gt;
&lt;td&gt;It comes with a lot of basic features&lt;/td&gt;
&lt;td&gt;It’s no longer supported by sony&lt;/td&gt;
&lt;/tr&gt;&lt;/p&gt;

&lt;p&gt;&lt;tr&gt;
&lt;td&gt;ports both WPF and (WinForms although it’s main focus is WinForms)&lt;/td&gt;
&lt;td&gt;It can be hard to debug if you are new to the system because of all the abstraction layers &lt;/td&gt;
&lt;/tr&gt;&lt;/p&gt;

&lt;p&gt;&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;A lot of third party dependencies&lt;/td&gt;
&lt;/tr&gt;&lt;/p&gt;

&lt;p&gt;&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Written in C# thus interoperation code will be required&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;&lt;/p&gt;

&lt;h2 id=&#34;qt&#34;&gt;QT&lt;/h2&gt;

&lt;p&gt;QT is a very large library with lots of functionality. It also took me considerably less effort to get my test working (approximately 4 hours). The interface looks well developed and understandable and the result is pretty good. The main downside however lies with one of its strengths. Because it’s such a vast library it can be quite hard to find the right class/system for the job. It might also be too large for what I need.&lt;/p&gt;

&lt;p&gt;&lt;i&gt;Summary:&lt;/i&gt;&lt;/p&gt;

&lt;table&gt;
&lt;tr&gt;
&lt;th&gt;Pros&lt;/th&gt;
&lt;th&gt;Cons&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Written in C  &lt;/td&gt;
&lt;td&gt;Not tailored to game development specifically&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Under active development/well maintained&lt;/td&gt;
&lt;td&gt;Because it’s such a big library it can be hard to find the right information&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Lots and lots of functionality&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

&lt;h2 id=&#34;wpf&#34;&gt;WPF&lt;/h2&gt;

&lt;p&gt;WPF is as bare bones as it gets. It only has a minimal amount of controls to start off with but the most important things are there. It’s also relatively easy to create your own controls/systems to suit your needs. It took me approximately 3 hours to get my sample working using WPF which was a pleasant surprise. WPF is written in C#, giving you a bit more control over directory operations which is nice when creating an editor.&lt;/p&gt;

&lt;p&gt;&lt;i&gt;Summary:&lt;/i&gt;&lt;/p&gt;

&lt;table&gt;
&lt;tr&gt;
&lt;th&gt;Pros&lt;/th&gt;
&lt;th&gt;Cons&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Its newer than WinForms&lt;/td&gt;
&lt;td&gt;Almost everything has to be built from scratch&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Clear distinction between mark-up and behaviour&lt;/td&gt;
&lt;td&gt;Written in C# thus interoperation code will be required&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Easy to create new controls&lt;/td&gt;
&lt;td&gt;Not yet many third party controls available&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Lots of controllability&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Build around data binding&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;&lt;p&gt;
Looking back at the pros and cons of all three frameworks it becomes clear that there are 2 main contenders, namely &lt;b&gt;QT&lt;/b&gt; and &lt;b&gt;WPF&lt;/b&gt;. On one hand QT is built in C   which is fast. QT also has lots of out of the box functionality. WPF on the other hand offers lots of control and an easy to understand interface.
In the end, I decided to go with WPF since I have the time to develop the tools and the controllability is really tempting. Choosing for WPF will also keep my dependencies to a minimum (at the cost of some overhead that comes with C# and the .NET framework). One downside is the requirement of writing an interoperation layer. But since we decided that the editor will be a separate process from the engine this would also be required with a C   application (albeit slightly less work).
&lt;/p&gt;
 &lt;/p&gt;

&lt;h2 id=&#34;further-reading&#34;&gt;Further reading&lt;/h2&gt;

&lt;p&gt;&lt;b&gt;ATF:&lt;/b&gt; &lt;a href=&#34;https://github.com/SonyWWS/ATF/wiki&#34;&gt;https://github.com/SonyWWS/ATF/wiki&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;WPF:&lt;/b&gt; &lt;a href=&#34;https://docs.microsoft.com/en-us/dotnet/framework/wpf/index&#34;&gt;https://docs.microsoft.com/en-us/dotnet/framework/wpf/index&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;b&gt;QT:&lt;/b&gt; &lt;a href=&#34;https://www.qt.io/&#34;&gt;https://www.qt.io/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Custom Physics</title>
      <link>https://stanpepels.github.io/post/custom-physics/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>https://stanpepels.github.io/post/custom-physics/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Tools for fools</title>
      <link>https://stanpepels.github.io/post/tools-for-fools/</link>
      <pubDate>Wed, 20 Apr 2016 00:00:00 +0200</pubDate>
      
      <guid>https://stanpepels.github.io/post/tools-for-fools/</guid>
      <description>

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;First of all I have to apologise for being a week late with this post. You would all get a cookie if I knew how to get it to you &lt;em&gt;(Editor note: No rights can be deduced from this statement)&lt;/em&gt;, but I don’t, so… Without further ado, let’s do this.&lt;/p&gt;

&lt;p&gt;Welcome to the most interesting and important update of them all, the tools update! We hope to inform you guys on the current status of our intuitive asset pipeline. We’ll cover the new features that come with our tools and give a quick showcase on how to use them.&lt;/p&gt;

&lt;h2 id=&#34;what-is-this-asset-pipeline-you-speak-of&#34;&gt;What is this asset pipeline you speak of?&lt;/h2&gt;

&lt;p&gt;The way most people will see the asset pipeline is through its user-friendly command line interface. Looks can be deceiving, as this seemingly simple tool is in fact very powerful. If you’re used to other command line tools you’ll know they are a pain to use. Unfortunately, this one is not much different but we tried to make it as streamlined as possible.&lt;/p&gt;

&lt;p&gt;First let me explain the main goal of the tool and why we need it. Its main goal is to take raw assets created in software such as Maya and convert them to a game ready format.&lt;/p&gt;

&lt;h2 id=&#34;so-why-do-we-need-to-convert-assets&#34;&gt;So why do we need to convert assets?&lt;/h2&gt;

&lt;p&gt;Well, the main reason is that certain file types are faster to read and / or take up less space on your disk. Of course having minute long load times or gigabyte size downloads are not on our wishlist. So in order to convert the raw files we build a tool that converts the assets for you because unless you are some kind of robot, it will take you ages to convert the files by hand.&lt;/p&gt;

&lt;p&gt;With that quick explanation out of the way let’s talk about how to use this tool and what features it supports.
We already support a bunch of the most common formats, such as
- the &lt;strong&gt;.fbx&lt;/strong&gt; and &lt;strong&gt;.obj&lt;/strong&gt; model formats,
- the &lt;strong&gt;.png&lt;/strong&gt;, &lt;strong&gt;.jpeg&lt;/strong&gt;, &lt;strong&gt;.bmp&lt;/strong&gt;, &lt;strong&gt;.dds&lt;/strong&gt; and &lt;strong&gt;.tga&lt;/strong&gt; (HDR is still being worked on) texture formats,
- and shaders written in the &lt;strong&gt;High Level Shader Language&lt;/strong&gt; (HLSL)&lt;/p&gt;

&lt;p&gt;You use the tool by running it from the command line or by running the sulphur-builder.exe directly and type commands in the window that opens. Doing it via the .exe gives you a few more options such as setting the working directory.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://projectsulphur.com/blog-media/asset_convertor.gif&#34; alt=&#34;Gif of the current editor&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;so-it-s-all-done-via-commands&#34;&gt;So it’s all done via commands?&lt;/h2&gt;

&lt;p&gt;Well no, not anymore. For the first 6 weeks you had to use the command line tool as explained above. But at long last, we’ve finally started on an actual editor. This editor implements the asset pipeline via a nice GUI where you can simply drag and drop your files which then get converted immediately. In addition to this, the editor gives you the ability to manage your workspace folder structure and also allows you to view the assets in the engine via the scene view.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://projectsulphur.com/blog-media/editor.gif&#34; alt=&#34;Gif of the current editor&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;a-few-technical-nitbits&#34;&gt;A few technical nitbits&lt;/h2&gt;

&lt;p&gt;For starters, our materials are shader based. These shaders are automatically compiled for all three of our rendering APIs. In other words, a 300% productivity boost! You know what else kills your productivity? Having to restart the engine when it crashes &lt;s&gt;&lt;em&gt;(*cough* UE4 *cough*)&lt;/em&gt;&lt;/s&gt;. Well worry no more. Our editor and engine are completely separate applications communicating over the network. So next time you are running your broken rotation script, your work is safe! The editor will automatically recover, which is lightning-fast because all assets are shared.&lt;/p&gt;

&lt;h2 id=&#34;future-features&#34;&gt;Future features&lt;/h2&gt;

&lt;p&gt;Next to all the features mentioned above there is still a lot left to do. We would like to support a lot more assets than just textures, models and shaders. We also need to do a lot of work on the editor before its ready.&lt;/p&gt;

&lt;p&gt;For the asset pipeline the following is planned to be supported:
- Scripts
- Audio files
- Proper texture processing like compression
- HDR textures
- Support for the all new GL Transmission Format (GLTF)
- Fonts&lt;/p&gt;

&lt;p&gt;And for the editor the awesome things you can look forward to seeing are:
- Gizmos
- A hierarchy viewer
- A material property editor
- Project saving/loading
- World saving/loading
- Playback controls for the Sulphur Rewinder™ (more info on that soon)&lt;/p&gt;

&lt;h2 id=&#34;recap&#34;&gt;Recap&lt;/h2&gt;

&lt;p&gt;So to quickly recap: Our current tool set consists out of a command line tool and a very barebones editor. There is still a lot of work that needs to happen if we want to make these tools up to production standards but for now they suffice. We hope that this post has stilled your needs to know about our awesome tools. Next week our producer will give an overall update of the project so look forward to that!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
